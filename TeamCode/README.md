# TeamCode Module by FTC Team #15173

## Object recognition
We have used 2 methods of detecting objects. 
* First is based on TensorFlow
* The other one is based on [EasyOpenCV](https://github.com/OpenFTC/EasyOpenCV)


### TensorFlow
This method is based on machine learning. You train a model and use it to recognize objects in the camera stream.
We use [Teachable Machine](https://teachablemachine.withgoogle.com/train) to create TensorFlow compatible models. 
Watch [this video](https://www.youtube.com/watch?v=aeMWWvteF2U) to see how it was done in the Ultimate goal season.

Once you have built your model in the Teachable Machine, save it in **tflite floating** format.
The FTC implementation of tensorFlow processing last year did not work with `tflite` models generated by the Teachable Machine. For that reason we created our own module using several Google examples.
It is packaged in the [`tfrec` folder under TeamCode](https://github.com/MHSRoboticEagles/FtcRobotController/tree/1ad8e47f8932f2b5aa500d87c877d4dcd73968a8/TeamCode/src/main/java/org/firstinspires/ftc/teamcode/tfrec)


If you want to give it a try, do the following:

* Copy `tfrec` folder from our TeamCode repo and paste it into your TeamCode folder

* Locate build.dependencies.gradle file and add these lines to the dependencies block:
```
dependencies{
….

implementation('org.tensorflow:tensorflow-lite:2.0.0')
implementation('org.tensorflow:tensorflow-lite-gpu:2.0.0')
implementation('org.tensorflow:tensorflow-lite-support:0.0.0-nightly') { changing = true }
}
```

Last year we had to remove references to the older versions of the tensorflow-lite libraries that FTC uses. 
This year, there seems to be no conflicts, as FTC packaged everything in a different library. 

* Create `assets` folder under your TeamCode folder, unless you already have it
* Copy the files generated by the Teachable Machine into your `assets` folder. Each model is represented by 2 files:
    *.tflite file with the model
    *.txt file with labels.
It does not matter what you call them since you will be referencing the files by name in your code.

* For an example of how to consume the detection, take a look at [TeamCode/skills/GenericDetector](https://github.com/MHSRoboticEagles/FtcRobotController/blob/1ad8e47f8932f2b5aa500d87c877d4dcd73968a8/TeamCode/src/main/java/org/firstinspires/ftc/teamcode/skills/GenericDetector.java) class.
It is a wrapper of the tflite engine that we have in `tfrec` folder. This class is specific to the last season. Note that it is a runnable, to run on a separate thread. This is where we reference the file names of our model. Make sure to change them based on your model file names.
You can use [TeamCode/OpMOdes/GenericRecognitionTest](https://github.com/MHSRoboticEagles/FtcRobotController/blob/1ad8e47f8932f2b5aa500d87c877d4dcd73968a8/TeamCode/src/main/java/org/firstinspires/ftc/teamcode/OpModes/GenericRecognitionTest.java) as an example opmode that consumes the GenericDetector.
Both of these generic classes are meant to be a starting point from which you can build up the recognition logic for your specific needs.

Note that we initialize the detector in the “init” phase of the Op mode. 
It usually takes 3-5 seconds for the tflite engine to “warm up”. The idea is that by the time you press Start, the detection results are available.

### EasyOpenCV

[EasyOpenCV](https://github.com/OpenFTC/EasyOpenCV) is based on color analysis in the camera stream.
You define one or more viewport areas, typically described as rectangles, and let EasyOpenCV analyze the input and manipulate color channels. The analysis boils down to comparing the observed values with expected values that are specific to color(s) of the objects that you need to detect.
The detection logic is implemented in a pipeline class. In the 2021-22 season we are using [CVFrenzyPipeline](https://github.com/MHSRoboticEagles/FtcRobotController/blob/1ad8e47f8932f2b5aa500d87c877d4dcd73968a8/TeamCode/src/main/java/org/firstinspires/ftc/teamcode/CVRec/CVFrenzyPipeline.java)
[CVRingSearchPipeline](https://github.com/MHSRoboticEagles/FtcRobotController/blob/1ad8e47f8932f2b5aa500d87c877d4dcd73968a8/TeamCode/src/main/java/org/firstinspires/ftc/teamcode/CVRec/CVRingSearchPipeline.java)provides a more complex use case, where we split the viewport in multiple rectangles to detect the location of the object relative to the camera on the robot.